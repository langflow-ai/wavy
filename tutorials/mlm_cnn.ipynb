{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "\n",
    "# to implement F1 score for validation in a batch\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1macro(y_true, y_pred):\n",
    "    f_pos = f1_m(y_true, y_pred)\n",
    "    # negative version of the data and prediction\n",
    "    f_neg = f1_m(1-y_true, 1-K.clip(y_pred,0,1))\n",
    "    return (f_pos + f_neg)/2\n",
    "\n",
    "def cnnpred_2d(seq_len=60, n_features=82, n_filters=(8,8,8), droprate=0.1):\n",
    "    \"2D-CNNpred model according to the paper\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(seq_len, n_features, 1)),\n",
    "        Conv2D(n_filters[0], kernel_size=(1, n_features), activation=\"relu\"),\n",
    "        Conv2D(n_filters[1], kernel_size=(3,1), activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2,1)),\n",
    "        Conv2D(n_filters[2], kernel_size=(3,1), activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2,1)),\n",
    "        Flatten(),\n",
    "        Dropout(droprate),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def datagen(data, seq_len, batch_size, targetcol, kind):\n",
    "    \"As a generator to produce samples for Keras model\"\n",
    "    batch = []\n",
    "    while True:\n",
    "        # Pick one dataframe from the pool\n",
    "        key = random.choice(list(data.keys()))\n",
    "        df = data[key]\n",
    "        input_cols = [c for c in df.columns if c != targetcol]\n",
    "        index = df.index[df.index < TRAIN_TEST_CUTOFF]\n",
    "        split = int(len(index) * TRAIN_VALID_RATIO)\n",
    "        assert split > seq_len, \"Training data too small for sequence length {}\".format(seq_len)\n",
    "        if kind == 'train':\n",
    "            index = index[:split]   # range for the training set\n",
    "        elif kind == 'valid':\n",
    "            index = index[split:]   # range for the validation set\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # Pick one position, then clip a sequence length\n",
    "        while True:\n",
    "            t = random.choice(index)     # pick one time step\n",
    "            n = (df.index == t).argmax() # find its position in the dataframe\n",
    "            if n-seq_len+1 < 0:\n",
    "                continue # this sample is not enough for one sequence length\n",
    "            frame = df.iloc[n-seq_len+1:n+1]\n",
    "            batch.append([frame[input_cols].values, df.loc[t, targetcol]])\n",
    "            break\n",
    "        # if we get enough for a batch, dispatch\n",
    "        if len(batch) == batch_size:\n",
    "            X, y = zip(*batch)\n",
    "            X, y = np.expand_dims(np.array(X), 3), np.array(y)\n",
    "            yield X, y\n",
    "            batch = []\n",
    "\n",
    "def testgen(data, seq_len, targetcol):\n",
    "    \"Return array of all test samples\"\n",
    "    batch = []\n",
    "    for key, df in data.items():\n",
    "        input_cols = [c for c in df.columns if c != targetcol]\n",
    "        # find the start of test sample\n",
    "        t = df.index[df.index >= TRAIN_TEST_CUTOFF][0]\n",
    "        n = (df.index == t).argmax()\n",
    "        # extract sample using a sliding window\n",
    "        for i in range(n+1, len(df)+1):\n",
    "            frame = df.iloc[i-seq_len:i]\n",
    "            batch.append([frame[input_cols].values, frame[targetcol][-1]])\n",
    "    X, y = zip(*batch)\n",
    "    return np.expand_dims(np.array(X),3), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../data/cnn_dataset/\"\n",
    "TRAIN_TEST_CUTOFF = '2016-04-21'\n",
    "TRAIN_VALID_RATIO = 0.75\n",
    "\n",
    "# Read data into pandas DataFrames\n",
    "data = {}\n",
    "for filename in os.listdir(DATADIR):\n",
    "    if not filename.lower().endswith(\".csv\"):\n",
    "        continue # read only the CSV files\n",
    "    filepath = os.path.join(DATADIR, filename)\n",
    "    X = pd.read_csv(filepath, index_col=\"Date\", parse_dates=True)\n",
    "    # basic preprocessing: get the name, the classification\n",
    "    # Save the target variable as a column in dataframe for easier dropna()\n",
    "    name = X[\"Name\"][0]\n",
    "    del X[\"Name\"]\n",
    "    cols = X.columns\n",
    "    X[\"Target\"] = (X[\"Close\"].pct_change() > 0).astype(int)\n",
    "    X.dropna(inplace=True)\n",
    "    # Fit the standard scaler using the training dataset\n",
    "    index = X.index[X.index < TRAIN_TEST_CUTOFF]\n",
    "    index = index[:int(len(index) * TRAIN_VALID_RATIO)]\n",
    "    scaler = StandardScaler().fit(X.loc[index, cols])\n",
    "    # Save scale transformed dataframe\n",
    "    X[cols] = scaler.transform(X[cols])\n",
    "    data[name] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_len = 60\n",
    "batch_size = 128\n",
    "n_epochs = 20\n",
    "n_features = 82\n",
    "\n",
    "# Produce CNNpred as a binary classification problem\n",
    "model = cnnpred_2d(seq_len, n_features)\n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"acc\", f1macro])\n",
    "model.summary()  # print model structure to console\n",
    "\n",
    "# Set up callbacks and fit the model\n",
    "# We use custom validation score f1macro() and hence monitor for \"val_f1macro\"\n",
    "checkpoint_path = \"./cp2d-{epoch}-{val_f1macro:.2f}.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path,\n",
    "                    monitor='val_f1macro', mode=\"max\",\n",
    "                    verbose=0, save_best_only=True, save_weights_only=False, save_freq=\"epoch\")\n",
    "]\n",
    "model.fit(datagen(data, seq_len, batch_size, \"Target\", \"train\"),\n",
    "          validation_data=datagen(data, seq_len, batch_size, \"Target\", \"valid\"),\n",
    "          epochs=n_epochs, steps_per_epoch=400, validation_steps=10, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# Prepare test data\n",
    "test_data, test_target = testgen(data, seq_len, \"Target\")\n",
    "\n",
    "# Test the model\n",
    "test_out = model.predict(test_data)\n",
    "test_pred = (test_out > 0.5).astype(int)\n",
    "print(\"accuracy:\", accuracy_score(test_pred, test_target))\n",
    "print(\"MAE:\", mean_absolute_error(test_pred, test_target))\n",
    "print(\"F1:\", f1_score(test_pred, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAVY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import wavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wq/x42bvx051z150nzjrrzlcm2m0000gn/T/ipykernel_20398/2898391816.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Close', 1)\n",
      "/var/folders/wq/x42bvx051z150nzjrrzlcm2m0000gn/T/ipykernel_20398/2898391816.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Close', 1)\n",
      "/var/folders/wq/x42bvx051z150nzjrrzlcm2m0000gn/T/ipykernel_20398/2898391816.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Close', 1)\n",
      "/var/folders/wq/x42bvx051z150nzjrrzlcm2m0000gn/T/ipykernel_20398/2898391816.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Close', 1)\n",
      "/var/folders/wq/x42bvx051z150nzjrrzlcm2m0000gn/T/ipykernel_20398/2898391816.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('Close', 1)\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"NASDAQ\", \"NYSE\", \"RUSSELL\", \"SP\", \"DJI\"]\n",
    "\n",
    "xs_train = []\n",
    "ys_train = []\n",
    "\n",
    "xs_val = []\n",
    "ys_val = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = pd.read_csv(f\"../data/cnn_dataset/Processed_{ticker}.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "    target = (df.Close.pct_change() > 0).astype(int)\n",
    "    df = df.drop('Close', 1)\n",
    "    df = df.dropna()\n",
    "    df = df[df.columns[-10:]]\n",
    "\n",
    "    scaler = StandardScaler().fit(df)\n",
    "    # Save scale transformed dataframe\n",
    "    df = pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
    "    df['target'] = target\n",
    "\n",
    "    x, y = wavy.create_panels(df, 60, 1)\n",
    "    y = y['target']\n",
    "\n",
    "    x_train = x.train.values\n",
    "    x_val = x.val.values\n",
    "\n",
    "    y_train = y.train.values.squeeze()\n",
    "    y_val = y.val.values.squeeze()\n",
    "\n",
    "    xs_train.extend(x_train)\n",
    "    ys_train.extend(y_train)\n",
    "    xs_val.extend(x_val)\n",
    "    ys_val.extend(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_81 (Conv2D)          (None, 60, 1, 8)          96        \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 58, 1, 8)          200       \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 29, 1, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 27, 1, 8)          200       \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 13, 1, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 104)               0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 104)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4369 - acc: 0.5950 - f1macro: 0.2975 - val_loss: 0.5942 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 591us/step - loss: 0.4229 - acc: 0.5800 - f1macro: 0.2900 - val_loss: 0.5983 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.4659 - acc: 0.5350 - f1macro: 0.2675 - val_loss: 0.5987 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.4756 - acc: 0.5250 - f1macro: 0.2625 - val_loss: 0.5993 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 594us/step - loss: 0.4402 - acc: 0.5600 - f1macro: 0.2800 - val_loss: 0.5994 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 587us/step - loss: 0.4504 - acc: 0.5500 - f1macro: 0.2750 - val_loss: 0.5997 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 711us/step - loss: 0.4900 - acc: 0.5100 - f1macro: 0.2550 - val_loss: 0.5997 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.4854 - acc: 0.5150 - f1macro: 0.2575 - val_loss: 0.5999 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 594us/step - loss: 0.4352 - acc: 0.5650 - f1macro: 0.2825 - val_loss: 0.5999 - val_acc: 0.4000 - val_f1macro: 0.2000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.4750 - acc: 0.5250 - f1macro: 0.2625 - val_loss: 0.5999 - val_acc: 0.4000 - val_f1macro: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c475c1c0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnnpred_2d(x.timesteps, len(x.columns))\n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"acc\", f1macro])\n",
    "model.summary()  # print model structure to console\n",
    "\n",
    "model.fit(np.array(xs_train), np.array(ys_train), validation_data=(np.array(xs_val), np.array(ys_val)), epochs=10, steps_per_epoch=200, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ba5b5620a693d47f2a3ef632e41f4be50f64c5815015773705d3d1d57940ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
